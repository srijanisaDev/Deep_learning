{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "51bfcb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade protobuf\n",
    "# %pip install --upgrade tensorflow      ## running this at the top after restarting the kernel deals with the import tensorflow error that occured in the later part of the code ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "54b48f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ba5d40a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "29a9ffb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "490adb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0.221898\n",
       "Glucose                     0.466581\n",
       "BloodPressure               0.065068\n",
       "SkinThickness               0.074752\n",
       "Insulin                     0.130548\n",
       "BMI                         0.292695\n",
       "DiabetesPedigreeFunction    0.173844\n",
       "Age                         0.238356\n",
       "Outcome                     1.000000\n",
       "Name: Outcome, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "293f1ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,:-1].values\n",
    "y =df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f3c02e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]],\n",
       "      shape=(768, 8))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a8a39f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9c98b9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c6d1877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "14e343ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cfb57d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cc8e18f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b3f8cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2 , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0af769e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6d06d0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KIIT0001\\Desktop\\Deep_learning\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32,activation='relu',input_dim = 8))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f7c9e316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6889 - loss: 0.6047 - val_accuracy: 0.7792 - val_loss: 0.5558\n",
      "Epoch 2/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7345 - loss: 0.5620 - val_accuracy: 0.8312 - val_loss: 0.5245\n",
      "Epoch 3/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7606 - loss: 0.5319 - val_accuracy: 0.8182 - val_loss: 0.5057\n",
      "Epoch 4/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7655 - loss: 0.5125 - val_accuracy: 0.8247 - val_loss: 0.4929\n",
      "Epoch 5/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7736 - loss: 0.4983 - val_accuracy: 0.8117 - val_loss: 0.4858\n",
      "Epoch 6/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7769 - loss: 0.4868 - val_accuracy: 0.8117 - val_loss: 0.4809\n",
      "Epoch 7/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7736 - loss: 0.4785 - val_accuracy: 0.8052 - val_loss: 0.4771\n",
      "Epoch 8/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7785 - loss: 0.4717 - val_accuracy: 0.8052 - val_loss: 0.4738\n",
      "Epoch 9/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7785 - loss: 0.4665 - val_accuracy: 0.8052 - val_loss: 0.4722\n",
      "Epoch 10/10\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7785 - loss: 0.4617 - val_accuracy: 0.7792 - val_loss: 0.4722\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e3b146a620>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train , y_train ,batch_size=32 , epochs=10,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e4ca8b",
   "metadata": {},
   "source": [
    "The main problem here is till now we were initializing the neurons,optimizers,activation based on our own intuition .....but we can automate it using a library known as keras tuner "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6b0151",
   "metadata": {},
   "source": [
    "# 1. how to select appropriate optimizer\n",
    "# 2. no of nodes in a layer\n",
    "# 3. select number of layers\n",
    "# 4. all in one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "013a6e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32f4aa6",
   "metadata": {},
   "source": [
    "# How to select appropriate optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fcd4df10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32,activation='relu',input_dim = 8))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    optimizer = hp.Choice('optimizer',values = ['adam','sgd','rmsprop','adadelta'])\n",
    "\n",
    "    model.compile(optimizer = optimizer,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "20a3c55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from .\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(build_model,\n",
    "                        objective='val_accuracy',\n",
    "                        max_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8cd1c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(x_train,y_train,epochs = 5 , validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "00cfdefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': 'rmsprop'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "81bf7010",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KIIT0001\\Desktop\\Deep_learning\\venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 6 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dde0cca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m288\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">321</span> (1.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m321\u001b[0m (1.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">321</span> (1.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m321\u001b[0m (1.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "64a95346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7443 - loss: 0.5125 - val_accuracy: 0.7662 - val_loss: 0.5502\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7622 - loss: 0.4949 - val_accuracy: 0.7662 - val_loss: 0.5411\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7655 - loss: 0.4842 - val_accuracy: 0.7662 - val_loss: 0.5327\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7736 - loss: 0.4762 - val_accuracy: 0.7727 - val_loss: 0.5271\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7801 - loss: 0.4690 - val_accuracy: 0.7727 - val_loss: 0.5213\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7801 - loss: 0.4636 - val_accuracy: 0.7727 - val_loss: 0.5180\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7801 - loss: 0.4593 - val_accuracy: 0.7597 - val_loss: 0.5160\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7818 - loss: 0.4555 - val_accuracy: 0.7597 - val_loss: 0.5156\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7834 - loss: 0.4522 - val_accuracy: 0.7597 - val_loss: 0.5138\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7866 - loss: 0.4488 - val_accuracy: 0.7597 - val_loss: 0.5120\n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7866 - loss: 0.4464 - val_accuracy: 0.7792 - val_loss: 0.5113\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7834 - loss: 0.4442 - val_accuracy: 0.7662 - val_loss: 0.5119\n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7883 - loss: 0.4424 - val_accuracy: 0.7662 - val_loss: 0.5115\n",
      "Epoch 20/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7866 - loss: 0.4412 - val_accuracy: 0.7662 - val_loss: 0.5128\n",
      "Epoch 21/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7883 - loss: 0.4391 - val_accuracy: 0.7662 - val_loss: 0.5123\n",
      "Epoch 22/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7899 - loss: 0.4376 - val_accuracy: 0.7662 - val_loss: 0.5120\n",
      "Epoch 23/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7883 - loss: 0.4360 - val_accuracy: 0.7662 - val_loss: 0.5115\n",
      "Epoch 24/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7866 - loss: 0.4350 - val_accuracy: 0.7662 - val_loss: 0.5121\n",
      "Epoch 25/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7932 - loss: 0.4340 - val_accuracy: 0.7597 - val_loss: 0.5133\n",
      "Epoch 26/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7915 - loss: 0.4328 - val_accuracy: 0.7597 - val_loss: 0.5142\n",
      "Epoch 27/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7932 - loss: 0.4322 - val_accuracy: 0.7597 - val_loss: 0.5142\n",
      "Epoch 28/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7915 - loss: 0.4311 - val_accuracy: 0.7597 - val_loss: 0.5151\n",
      "Epoch 29/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7915 - loss: 0.4299 - val_accuracy: 0.7597 - val_loss: 0.5152\n",
      "Epoch 30/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7964 - loss: 0.4291 - val_accuracy: 0.7597 - val_loss: 0.5160\n",
      "Epoch 31/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7964 - loss: 0.4281 - val_accuracy: 0.7662 - val_loss: 0.5148\n",
      "Epoch 32/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7964 - loss: 0.4271 - val_accuracy: 0.7662 - val_loss: 0.5171\n",
      "Epoch 33/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7964 - loss: 0.4265 - val_accuracy: 0.7662 - val_loss: 0.5183\n",
      "Epoch 34/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7964 - loss: 0.4258 - val_accuracy: 0.7662 - val_loss: 0.5196\n",
      "Epoch 35/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7932 - loss: 0.4250 - val_accuracy: 0.7662 - val_loss: 0.5202\n",
      "Epoch 36/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7980 - loss: 0.4243 - val_accuracy: 0.7597 - val_loss: 0.5202\n",
      "Epoch 37/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7980 - loss: 0.4234 - val_accuracy: 0.7597 - val_loss: 0.5214\n",
      "Epoch 38/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8013 - loss: 0.4226 - val_accuracy: 0.7597 - val_loss: 0.5208\n",
      "Epoch 39/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7980 - loss: 0.4219 - val_accuracy: 0.7597 - val_loss: 0.5209\n",
      "Epoch 40/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7964 - loss: 0.4215 - val_accuracy: 0.7597 - val_loss: 0.5206\n",
      "Epoch 41/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8046 - loss: 0.4206 - val_accuracy: 0.7597 - val_loss: 0.5221\n",
      "Epoch 42/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7948 - loss: 0.4199 - val_accuracy: 0.7597 - val_loss: 0.5207\n",
      "Epoch 43/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7997 - loss: 0.4192 - val_accuracy: 0.7597 - val_loss: 0.5227\n",
      "Epoch 44/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8029 - loss: 0.4188 - val_accuracy: 0.7597 - val_loss: 0.5227\n",
      "Epoch 45/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7997 - loss: 0.4186 - val_accuracy: 0.7662 - val_loss: 0.5230\n",
      "Epoch 46/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8062 - loss: 0.4176 - val_accuracy: 0.7597 - val_loss: 0.5229\n",
      "Epoch 47/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8062 - loss: 0.4172 - val_accuracy: 0.7597 - val_loss: 0.5244\n",
      "Epoch 48/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7980 - loss: 0.4164 - val_accuracy: 0.7727 - val_loss: 0.5241\n",
      "Epoch 49/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7980 - loss: 0.4158 - val_accuracy: 0.7662 - val_loss: 0.5246\n",
      "Epoch 50/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7964 - loss: 0.4152 - val_accuracy: 0.7662 - val_loss: 0.5239\n",
      "Epoch 51/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8013 - loss: 0.4146 - val_accuracy: 0.7662 - val_loss: 0.5228\n",
      "Epoch 52/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8046 - loss: 0.4141 - val_accuracy: 0.7662 - val_loss: 0.5237\n",
      "Epoch 53/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8013 - loss: 0.4134 - val_accuracy: 0.7727 - val_loss: 0.5238\n",
      "Epoch 54/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7964 - loss: 0.4133 - val_accuracy: 0.7662 - val_loss: 0.5235\n",
      "Epoch 55/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7997 - loss: 0.4126 - val_accuracy: 0.7662 - val_loss: 0.5229\n",
      "Epoch 56/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8013 - loss: 0.4122 - val_accuracy: 0.7662 - val_loss: 0.5221\n",
      "Epoch 57/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8013 - loss: 0.4116 - val_accuracy: 0.7662 - val_loss: 0.5229\n",
      "Epoch 58/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8046 - loss: 0.4114 - val_accuracy: 0.7662 - val_loss: 0.5231\n",
      "Epoch 59/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7997 - loss: 0.4108 - val_accuracy: 0.7662 - val_loss: 0.5232\n",
      "Epoch 60/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8078 - loss: 0.4102 - val_accuracy: 0.7662 - val_loss: 0.5243\n",
      "Epoch 61/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8046 - loss: 0.4100 - val_accuracy: 0.7662 - val_loss: 0.5245\n",
      "Epoch 62/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8094 - loss: 0.4092 - val_accuracy: 0.7662 - val_loss: 0.5262\n",
      "Epoch 63/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8062 - loss: 0.4090 - val_accuracy: 0.7662 - val_loss: 0.5268\n",
      "Epoch 64/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8062 - loss: 0.4085 - val_accuracy: 0.7662 - val_loss: 0.5275\n",
      "Epoch 65/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8078 - loss: 0.4083 - val_accuracy: 0.7662 - val_loss: 0.5274\n",
      "Epoch 66/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8094 - loss: 0.4077 - val_accuracy: 0.7662 - val_loss: 0.5280\n",
      "Epoch 67/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8062 - loss: 0.4075 - val_accuracy: 0.7662 - val_loss: 0.5273\n",
      "Epoch 68/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8111 - loss: 0.4068 - val_accuracy: 0.7662 - val_loss: 0.5274\n",
      "Epoch 69/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8078 - loss: 0.4067 - val_accuracy: 0.7662 - val_loss: 0.5288\n",
      "Epoch 70/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8111 - loss: 0.4060 - val_accuracy: 0.7662 - val_loss: 0.5295\n",
      "Epoch 71/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8111 - loss: 0.4058 - val_accuracy: 0.7662 - val_loss: 0.5295\n",
      "Epoch 72/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8127 - loss: 0.4055 - val_accuracy: 0.7662 - val_loss: 0.5302\n",
      "Epoch 73/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8111 - loss: 0.4052 - val_accuracy: 0.7662 - val_loss: 0.5310\n",
      "Epoch 74/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8143 - loss: 0.4044 - val_accuracy: 0.7662 - val_loss: 0.5325\n",
      "Epoch 75/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8127 - loss: 0.4043 - val_accuracy: 0.7662 - val_loss: 0.5330\n",
      "Epoch 76/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8127 - loss: 0.4038 - val_accuracy: 0.7662 - val_loss: 0.5341\n",
      "Epoch 77/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8127 - loss: 0.4034 - val_accuracy: 0.7662 - val_loss: 0.5336\n",
      "Epoch 78/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8127 - loss: 0.4030 - val_accuracy: 0.7662 - val_loss: 0.5340\n",
      "Epoch 79/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8143 - loss: 0.4022 - val_accuracy: 0.7662 - val_loss: 0.5342\n",
      "Epoch 80/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8094 - loss: 0.4024 - val_accuracy: 0.7662 - val_loss: 0.5337\n",
      "Epoch 81/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8127 - loss: 0.4019 - val_accuracy: 0.7597 - val_loss: 0.5354\n",
      "Epoch 82/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8143 - loss: 0.4019 - val_accuracy: 0.7597 - val_loss: 0.5369\n",
      "Epoch 83/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8127 - loss: 0.4013 - val_accuracy: 0.7532 - val_loss: 0.5378\n",
      "Epoch 84/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8111 - loss: 0.4013 - val_accuracy: 0.7532 - val_loss: 0.5376\n",
      "Epoch 85/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8127 - loss: 0.4005 - val_accuracy: 0.7597 - val_loss: 0.5374\n",
      "Epoch 86/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8111 - loss: 0.4004 - val_accuracy: 0.7597 - val_loss: 0.5393\n",
      "Epoch 87/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8094 - loss: 0.4002 - val_accuracy: 0.7597 - val_loss: 0.5390\n",
      "Epoch 88/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8111 - loss: 0.3999 - val_accuracy: 0.7597 - val_loss: 0.5388\n",
      "Epoch 89/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8094 - loss: 0.3995 - val_accuracy: 0.7597 - val_loss: 0.5383\n",
      "Epoch 90/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8094 - loss: 0.3988 - val_accuracy: 0.7597 - val_loss: 0.5375\n",
      "Epoch 91/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8062 - loss: 0.3983 - val_accuracy: 0.7597 - val_loss: 0.5359\n",
      "Epoch 92/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8111 - loss: 0.3983 - val_accuracy: 0.7597 - val_loss: 0.5361\n",
      "Epoch 93/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8127 - loss: 0.3984 - val_accuracy: 0.7597 - val_loss: 0.5370\n",
      "Epoch 94/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8094 - loss: 0.3973 - val_accuracy: 0.7597 - val_loss: 0.5365\n",
      "Epoch 95/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8111 - loss: 0.3973 - val_accuracy: 0.7597 - val_loss: 0.5364\n",
      "Epoch 96/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8127 - loss: 0.3964 - val_accuracy: 0.7597 - val_loss: 0.5353\n",
      "Epoch 97/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8111 - loss: 0.3962 - val_accuracy: 0.7597 - val_loss: 0.5345\n",
      "Epoch 98/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8111 - loss: 0.3962 - val_accuracy: 0.7597 - val_loss: 0.5353\n",
      "Epoch 99/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8176 - loss: 0.3954 - val_accuracy: 0.7597 - val_loss: 0.5363\n",
      "Epoch 100/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8127 - loss: 0.3951 - val_accuracy: 0.7662 - val_loss: 0.5375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e3b13c99c0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=32,epochs=100,initial_epoch=6,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b776e4f",
   "metadata": {},
   "source": [
    "# how to get number of nodes in a layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "706933ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    units = hp.Int('units',min_value = 8,max_value = 128,step=8)\n",
    "    model.add(Dense(units=units,activation='relu',input_dim=8))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7a900660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from mydir\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(build_model,\n",
    "                        objective='val_accuracy',\n",
    "                        max_trials=5,\n",
    "                        directory='mydir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ed078279",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(x_train, y_train,epochs = 5,validation_data= (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c714946c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'units': 72}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "324a16df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d9c57835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7687 - loss: 0.4663  \n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7785 - loss: 0.4566 \n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7704 - loss: 0.4512 \n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7736 - loss: 0.4481 \n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7769 - loss: 0.4444 \n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7866 - loss: 0.4417 \n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7736 - loss: 0.4394 \n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7785 - loss: 0.4377 \n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7769 - loss: 0.4355 \n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7785 - loss: 0.4344 \n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7785 - loss: 0.4330 \n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7834 - loss: 0.4316 \n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7801 - loss: 0.4294 \n",
      "Epoch 20/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7866 - loss: 0.4282 \n",
      "Epoch 21/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7850 - loss: 0.4267 \n",
      "Epoch 22/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7932 - loss: 0.4259 \n",
      "Epoch 23/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7866 - loss: 0.4249 \n",
      "Epoch 24/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7883 - loss: 0.4240 \n",
      "Epoch 25/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7915 - loss: 0.4226 \n",
      "Epoch 26/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7850 - loss: 0.4215 \n",
      "Epoch 27/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7915 - loss: 0.4211 \n",
      "Epoch 28/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7866 - loss: 0.4203 \n",
      "Epoch 29/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7866 - loss: 0.4189 \n",
      "Epoch 30/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7915 - loss: 0.4185 \n",
      "Epoch 31/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7883 - loss: 0.4171\n",
      "Epoch 32/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7834 - loss: 0.4170\n",
      "Epoch 33/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7915 - loss: 0.4158 \n",
      "Epoch 34/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7915 - loss: 0.4154 \n",
      "Epoch 35/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7997 - loss: 0.4150  \n",
      "Epoch 36/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7964 - loss: 0.4138 \n",
      "Epoch 37/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7997 - loss: 0.4132 \n",
      "Epoch 38/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7997 - loss: 0.4123 \n",
      "Epoch 39/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7964 - loss: 0.4118 \n",
      "Epoch 40/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7948 - loss: 0.4105 \n",
      "Epoch 41/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7964 - loss: 0.4100 \n",
      "Epoch 42/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7948 - loss: 0.4096 \n",
      "Epoch 43/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7997 - loss: 0.4088 \n",
      "Epoch 44/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8013 - loss: 0.4086 \n",
      "Epoch 45/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7997 - loss: 0.4080 \n",
      "Epoch 46/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8029 - loss: 0.4072 \n",
      "Epoch 47/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8029 - loss: 0.4068 \n",
      "Epoch 48/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7980 - loss: 0.4069 \n",
      "Epoch 49/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8029 - loss: 0.4050 \n",
      "Epoch 50/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8046 - loss: 0.4053 \n",
      "Epoch 51/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8078 - loss: 0.4048 \n",
      "Epoch 52/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8046 - loss: 0.4043 \n",
      "Epoch 53/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8013 - loss: 0.4039 \n",
      "Epoch 54/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7980 - loss: 0.4032 \n",
      "Epoch 55/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8046 - loss: 0.4024 \n",
      "Epoch 56/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8029 - loss: 0.4023 \n",
      "Epoch 57/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8013 - loss: 0.4014 \n",
      "Epoch 58/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8013 - loss: 0.4015 \n",
      "Epoch 59/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8078 - loss: 0.4005 \n",
      "Epoch 60/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8046 - loss: 0.4003 \n",
      "Epoch 61/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8062 - loss: 0.3990 \n",
      "Epoch 62/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8046 - loss: 0.3993 \n",
      "Epoch 63/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8062 - loss: 0.3987 \n",
      "Epoch 64/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8062 - loss: 0.3980 \n",
      "Epoch 65/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8046 - loss: 0.3978 \n",
      "Epoch 66/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8111 - loss: 0.3965 \n",
      "Epoch 67/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8078 - loss: 0.3967 \n",
      "Epoch 68/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8094 - loss: 0.3964 \n",
      "Epoch 69/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8078 - loss: 0.3960 \n",
      "Epoch 70/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8062 - loss: 0.3956 \n",
      "Epoch 71/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8078 - loss: 0.3947 \n",
      "Epoch 72/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8078 - loss: 0.3953 \n",
      "Epoch 73/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8111 - loss: 0.3939 \n",
      "Epoch 74/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8111 - loss: 0.3940 \n",
      "Epoch 75/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8127 - loss: 0.3935 \n",
      "Epoch 76/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8143 - loss: 0.3929 \n",
      "Epoch 77/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8127 - loss: 0.3923 \n",
      "Epoch 78/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8143 - loss: 0.3922 \n",
      "Epoch 79/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8176 - loss: 0.3917 \n",
      "Epoch 80/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8160 - loss: 0.3911 \n",
      "Epoch 81/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8143 - loss: 0.3905 \n",
      "Epoch 82/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8176 - loss: 0.3908 \n",
      "Epoch 83/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8127 - loss: 0.3902 \n",
      "Epoch 84/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8094 - loss: 0.3900 \n",
      "Epoch 85/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8143 - loss: 0.3891 \n",
      "Epoch 86/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8176 - loss: 0.3891 \n",
      "Epoch 87/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8160 - loss: 0.3882 \n",
      "Epoch 88/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8127 - loss: 0.3883 \n",
      "Epoch 89/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8208 - loss: 0.3871 \n",
      "Epoch 90/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8176 - loss: 0.3869 \n",
      "Epoch 91/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8127 - loss: 0.3868 \n",
      "Epoch 92/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8160 - loss: 0.3862 \n",
      "Epoch 93/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8225 - loss: 0.3859\n",
      "Epoch 94/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8143 - loss: 0.3857 \n",
      "Epoch 95/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8241 - loss: 0.3845 \n",
      "Epoch 96/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8225 - loss: 0.3844 \n",
      "Epoch 97/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8241 - loss: 0.3838 \n",
      "Epoch 98/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8192 - loss: 0.3840 \n",
      "Epoch 99/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8241 - loss: 0.3828 \n",
      "Epoch 100/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8225 - loss: 0.3833 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e3b13d22b0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=32,epochs=100,initial_epoch=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e770750",
   "metadata": {},
   "source": [
    "# select number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4e7f6d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(72,activation='relu',input_dim = 8))\n",
    "    for i in range (hp.Int('num_layers',min_value = 1 , max_value = 10)):\n",
    "        model.add(Dense(72,activation='relu'))\n",
    "\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e122c16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from mydir\\num_layers\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(build_model,\n",
    "                        objective='val_accuracy',\n",
    "                        max_trials=3,\n",
    "                        directory = 'mydir',\n",
    "                        project_name = 'num_layers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "284c6d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(x_train,y_train,epochs=5,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3388e537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_layers': 6}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ce5fa446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KIIT0001\\Desktop\\Deep_learning\\venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "115eca7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7801 - loss: 0.4604 - val_accuracy: 0.7403 - val_loss: 0.5268\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7964 - loss: 0.4307 - val_accuracy: 0.7727 - val_loss: 0.5516\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8013 - loss: 0.4112 - val_accuracy: 0.7727 - val_loss: 0.5485\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8078 - loss: 0.4147 - val_accuracy: 0.7468 - val_loss: 0.5699\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8257 - loss: 0.3986 - val_accuracy: 0.7403 - val_loss: 0.6000\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8225 - loss: 0.3922 - val_accuracy: 0.7403 - val_loss: 0.5433\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8241 - loss: 0.3883 - val_accuracy: 0.7143 - val_loss: 0.5866\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8355 - loss: 0.3568 - val_accuracy: 0.6558 - val_loss: 0.6858\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8339 - loss: 0.3665 - val_accuracy: 0.7403 - val_loss: 0.6450\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8664 - loss: 0.3400 - val_accuracy: 0.7662 - val_loss: 0.6468\n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8469 - loss: 0.3417 - val_accuracy: 0.7208 - val_loss: 0.6151\n",
      "Epoch 18/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8648 - loss: 0.3136 - val_accuracy: 0.6753 - val_loss: 0.7240\n",
      "Epoch 19/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8632 - loss: 0.3128 - val_accuracy: 0.6948 - val_loss: 0.7374\n",
      "Epoch 20/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8925 - loss: 0.2833 - val_accuracy: 0.7273 - val_loss: 0.6872\n",
      "Epoch 21/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8844 - loss: 0.2784 - val_accuracy: 0.7013 - val_loss: 0.8107\n",
      "Epoch 22/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9072 - loss: 0.2490 - val_accuracy: 0.7468 - val_loss: 0.8759\n",
      "Epoch 23/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9007 - loss: 0.2459 - val_accuracy: 0.6883 - val_loss: 1.1518\n",
      "Epoch 24/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8958 - loss: 0.2603 - val_accuracy: 0.6429 - val_loss: 0.9793\n",
      "Epoch 25/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9088 - loss: 0.2310 - val_accuracy: 0.7013 - val_loss: 0.8725\n",
      "Epoch 26/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9283 - loss: 0.2063 - val_accuracy: 0.7143 - val_loss: 0.8085\n",
      "Epoch 27/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9267 - loss: 0.2022 - val_accuracy: 0.7143 - val_loss: 0.9654\n",
      "Epoch 28/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9202 - loss: 0.1906 - val_accuracy: 0.6558 - val_loss: 1.2670\n",
      "Epoch 29/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9349 - loss: 0.1695 - val_accuracy: 0.6818 - val_loss: 1.0343\n",
      "Epoch 30/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9251 - loss: 0.1900 - val_accuracy: 0.7013 - val_loss: 1.0743\n",
      "Epoch 31/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9528 - loss: 0.1502 - val_accuracy: 0.7078 - val_loss: 0.9837\n",
      "Epoch 32/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9463 - loss: 0.1382 - val_accuracy: 0.7143 - val_loss: 1.2110\n",
      "Epoch 33/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9430 - loss: 0.1418 - val_accuracy: 0.6883 - val_loss: 1.1011\n",
      "Epoch 34/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9544 - loss: 0.1260 - val_accuracy: 0.7338 - val_loss: 1.2784\n",
      "Epoch 35/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9349 - loss: 0.1760 - val_accuracy: 0.7338 - val_loss: 1.1225\n",
      "Epoch 36/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9674 - loss: 0.0931 - val_accuracy: 0.7013 - val_loss: 1.3426\n",
      "Epoch 37/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9495 - loss: 0.1375 - val_accuracy: 0.7143 - val_loss: 1.3219\n",
      "Epoch 38/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9723 - loss: 0.0924 - val_accuracy: 0.7143 - val_loss: 1.3906\n",
      "Epoch 39/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9674 - loss: 0.0939 - val_accuracy: 0.6883 - val_loss: 1.5261\n",
      "Epoch 40/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9674 - loss: 0.1152 - val_accuracy: 0.7143 - val_loss: 1.2671\n",
      "Epoch 41/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9723 - loss: 0.0688 - val_accuracy: 0.7078 - val_loss: 1.3674\n",
      "Epoch 42/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9658 - loss: 0.0883 - val_accuracy: 0.6753 - val_loss: 1.6439\n",
      "Epoch 43/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9658 - loss: 0.0844 - val_accuracy: 0.7338 - val_loss: 1.5064\n",
      "Epoch 44/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9853 - loss: 0.0487 - val_accuracy: 0.6883 - val_loss: 1.7919\n",
      "Epoch 45/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9625 - loss: 0.1189 - val_accuracy: 0.7078 - val_loss: 1.4303\n",
      "Epoch 46/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9919 - loss: 0.0310 - val_accuracy: 0.7273 - val_loss: 1.4300\n",
      "Epoch 47/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9707 - loss: 0.0975 - val_accuracy: 0.7013 - val_loss: 1.6187\n",
      "Epoch 48/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9723 - loss: 0.0718 - val_accuracy: 0.7143 - val_loss: 1.5312\n",
      "Epoch 49/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9853 - loss: 0.0533 - val_accuracy: 0.7338 - val_loss: 1.8240\n",
      "Epoch 50/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9837 - loss: 0.0543 - val_accuracy: 0.6753 - val_loss: 1.7562\n",
      "Epoch 51/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9886 - loss: 0.0403 - val_accuracy: 0.7338 - val_loss: 2.1068\n",
      "Epoch 52/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9756 - loss: 0.0653 - val_accuracy: 0.6494 - val_loss: 2.2249\n",
      "Epoch 53/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9853 - loss: 0.0582 - val_accuracy: 0.7078 - val_loss: 1.7640\n",
      "Epoch 54/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9919 - loss: 0.0383 - val_accuracy: 0.6818 - val_loss: 2.0090\n",
      "Epoch 55/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9821 - loss: 0.0572 - val_accuracy: 0.6883 - val_loss: 2.0365\n",
      "Epoch 56/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9886 - loss: 0.0378 - val_accuracy: 0.6688 - val_loss: 2.5624\n",
      "Epoch 57/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9805 - loss: 0.0601 - val_accuracy: 0.6883 - val_loss: 1.9200\n",
      "Epoch 58/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9984 - loss: 0.0060 - val_accuracy: 0.6623 - val_loss: 2.4792\n",
      "Epoch 59/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9691 - loss: 0.0979 - val_accuracy: 0.7013 - val_loss: 1.9920\n",
      "Epoch 60/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9788 - loss: 0.0515 - val_accuracy: 0.6753 - val_loss: 2.4024\n",
      "Epoch 61/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9886 - loss: 0.0277 - val_accuracy: 0.6948 - val_loss: 2.0161\n",
      "Epoch 62/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9902 - loss: 0.0307 - val_accuracy: 0.6883 - val_loss: 2.1690\n",
      "Epoch 63/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9984 - loss: 0.0071 - val_accuracy: 0.7143 - val_loss: 2.6773\n",
      "Epoch 64/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9805 - loss: 0.0835 - val_accuracy: 0.6883 - val_loss: 2.1814\n",
      "Epoch 65/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.6883 - val_loss: 2.4621\n",
      "Epoch 66/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7273 - val_loss: 2.4205\n",
      "Epoch 67/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0775 - val_accuracy: 0.7143 - val_loss: 2.3646\n",
      "Epoch 68/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9837 - loss: 0.0508 - val_accuracy: 0.6948 - val_loss: 2.3282\n",
      "Epoch 69/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.6818 - val_loss: 2.5292\n",
      "Epoch 70/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.7013 - val_loss: 2.8680\n",
      "Epoch 71/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9821 - loss: 0.0661 - val_accuracy: 0.6494 - val_loss: 2.6902\n",
      "Epoch 72/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9853 - loss: 0.0442 - val_accuracy: 0.7338 - val_loss: 2.2385\n",
      "Epoch 73/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9870 - loss: 0.0570 - val_accuracy: 0.6883 - val_loss: 2.3700\n",
      "Epoch 74/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9967 - loss: 0.0176 - val_accuracy: 0.7078 - val_loss: 2.2107\n",
      "Epoch 75/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9935 - loss: 0.0252 - val_accuracy: 0.6948 - val_loss: 2.5287\n",
      "Epoch 76/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9935 - loss: 0.0410 - val_accuracy: 0.6753 - val_loss: 2.3721\n",
      "Epoch 77/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9658 - loss: 0.0895 - val_accuracy: 0.7013 - val_loss: 2.2402\n",
      "Epoch 78/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.7013 - val_loss: 2.4455\n",
      "Epoch 79/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.7013 - val_loss: 2.6097\n",
      "Epoch 80/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7013 - val_loss: 3.1101\n",
      "Epoch 81/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9723 - loss: 0.1285 - val_accuracy: 0.6753 - val_loss: 2.4157\n",
      "Epoch 82/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9984 - loss: 0.0130 - val_accuracy: 0.7013 - val_loss: 2.5144\n",
      "Epoch 83/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 8.9135e-04 - val_accuracy: 0.6948 - val_loss: 2.7123\n",
      "Epoch 84/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.0964e-04 - val_accuracy: 0.7078 - val_loss: 2.8494\n",
      "Epoch 85/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.9831e-04 - val_accuracy: 0.7078 - val_loss: 3.0207\n",
      "Epoch 86/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.6636e-04 - val_accuracy: 0.6883 - val_loss: 3.3575\n",
      "Epoch 87/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9756 - loss: 0.1041 - val_accuracy: 0.6494 - val_loss: 3.4112\n",
      "Epoch 88/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9886 - loss: 0.0401 - val_accuracy: 0.7013 - val_loss: 2.9965\n",
      "Epoch 89/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.2852e-04 - val_accuracy: 0.7013 - val_loss: 2.9350\n",
      "Epoch 90/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 3.1649e-04 - val_accuracy: 0.6948 - val_loss: 3.0101\n",
      "Epoch 91/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 2.0173e-04 - val_accuracy: 0.6948 - val_loss: 3.1974\n",
      "Epoch 92/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 1.1748e-04 - val_accuracy: 0.6883 - val_loss: 3.3657\n",
      "Epoch 93/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9984 - loss: 0.0057 - val_accuracy: 0.6883 - val_loss: 4.0708\n",
      "Epoch 94/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9837 - loss: 0.0787 - val_accuracy: 0.6818 - val_loss: 2.8558\n",
      "Epoch 95/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9902 - loss: 0.0242 - val_accuracy: 0.6818 - val_loss: 3.3729\n",
      "Epoch 96/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9886 - loss: 0.0383 - val_accuracy: 0.7143 - val_loss: 2.6940\n",
      "Epoch 97/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.7143 - val_loss: 2.7819\n",
      "Epoch 98/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.4908e-04 - val_accuracy: 0.7013 - val_loss: 3.1776\n",
      "Epoch 99/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9821 - loss: 0.0625 - val_accuracy: 0.7208 - val_loss: 2.5008\n",
      "Epoch 100/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.7273 - val_loss: 2.6445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e3b18a8f50>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=100,initial_epoch=6,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fa0eaa",
   "metadata": {},
   "source": [
    "\n",
    "# All in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f650dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    counter = 0\n",
    "\n",
    "    for i in range(hp.Int('num_layers',min_value =1,max_value=10)):\n",
    "        if counter == 0:\n",
    "            model.add(\n",
    "                Dense(\n",
    "                    hp.Int('units' + str(i) , min_value = 8 , max_value = 128 , step = 8),\n",
    "                   \n",
    "                    input_dim = 8\n",
    "                )\n",
    "            )\n",
    "\n",
    "        else :\n",
    "\n",
    "            model.add(\n",
    "                Dense(\n",
    "                    hp.Int('units' + str(i) , min_value = 8 , max_value = 128 , step = 8),\n",
    "                    optimizer = hp.Choice('activation' + str(i),values=['relu','tanh','sigmoid'])\n",
    "                    \n",
    "                )\n",
    "                \n",
    "            )\n",
    "            counter += 1\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=hp.Choice('optimizer',values=['rmsprop','adam','sgd','nadam','adadelta']),\n",
    "                  loss = 'binary_crossentropy',\n",
    "                  metrics=['accuracy'])  \n",
    "\n",
    "\n",
    "\n",
    "    return model   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bb6886c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(build_model,\n",
    "                        objective='val_accuracy',\n",
    "                        max_trials=3,\n",
    "                        directory=\"mydir\",\n",
    "                        project_name = 'final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6e0d1693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 00m 03s]\n",
      "val_accuracy: 0.7532467246055603\n",
      "\n",
      "Best val_accuracy So Far: 0.7792207598686218\n",
      "Total elapsed time: 00h 00m 09s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(x_train,y_train,epochs=5,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b66598cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_layers': 9,\n",
       " 'units0': 72,\n",
       " 'optimizer': 'rmsprop',\n",
       " 'units1': 8,\n",
       " 'units2': 8,\n",
       " 'units3': 8,\n",
       " 'units4': 8,\n",
       " 'units5': 8,\n",
       " 'units6': 8,\n",
       " 'units7': 8,\n",
       " 'units8': 8}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ce5b4fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KIIT0001\\Desktop\\Deep_learning\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\KIIT0001\\Desktop\\Deep_learning\\venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:797: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f6320033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7606 - loss: 0.4829 - val_accuracy: 0.7403 - val_loss: 0.5181\n",
      "Epoch 8/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7720 - loss: 0.4798 - val_accuracy: 0.7597 - val_loss: 0.5098\n",
      "Epoch 9/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7622 - loss: 0.4762 - val_accuracy: 0.7468 - val_loss: 0.5188\n",
      "Epoch 10/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7769 - loss: 0.4777 - val_accuracy: 0.7792 - val_loss: 0.5136\n",
      "Epoch 11/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7687 - loss: 0.4754 - val_accuracy: 0.7662 - val_loss: 0.5114\n",
      "Epoch 12/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7687 - loss: 0.4750 - val_accuracy: 0.7338 - val_loss: 0.5270\n",
      "Epoch 13/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7736 - loss: 0.4767 - val_accuracy: 0.7338 - val_loss: 0.5167\n",
      "Epoch 14/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7736 - loss: 0.4772 - val_accuracy: 0.7208 - val_loss: 0.5229\n",
      "Epoch 15/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7671 - loss: 0.4766 - val_accuracy: 0.7403 - val_loss: 0.5130\n",
      "Epoch 16/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7752 - loss: 0.4751 - val_accuracy: 0.7403 - val_loss: 0.5314\n",
      "Epoch 17/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7671 - loss: 0.4781 - val_accuracy: 0.7532 - val_loss: 0.5187\n",
      "Epoch 18/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7687 - loss: 0.4776 - val_accuracy: 0.7532 - val_loss: 0.5129\n",
      "Epoch 19/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7655 - loss: 0.4771 - val_accuracy: 0.7532 - val_loss: 0.5095\n",
      "Epoch 20/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7704 - loss: 0.4746 - val_accuracy: 0.7532 - val_loss: 0.5228\n",
      "Epoch 21/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7622 - loss: 0.4771 - val_accuracy: 0.7468 - val_loss: 0.5269\n",
      "Epoch 22/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7638 - loss: 0.4755 - val_accuracy: 0.7468 - val_loss: 0.5184\n",
      "Epoch 23/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7752 - loss: 0.4756 - val_accuracy: 0.7727 - val_loss: 0.5120\n",
      "Epoch 24/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7671 - loss: 0.4760 - val_accuracy: 0.7727 - val_loss: 0.5097\n",
      "Epoch 25/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7818 - loss: 0.4759 - val_accuracy: 0.7727 - val_loss: 0.5084\n",
      "Epoch 26/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7736 - loss: 0.4744 - val_accuracy: 0.7597 - val_loss: 0.5086\n",
      "Epoch 27/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7736 - loss: 0.4771 - val_accuracy: 0.7338 - val_loss: 0.5169\n",
      "Epoch 28/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7655 - loss: 0.4745 - val_accuracy: 0.7532 - val_loss: 0.5073\n",
      "Epoch 29/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7720 - loss: 0.4771 - val_accuracy: 0.7468 - val_loss: 0.5099\n",
      "Epoch 30/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7687 - loss: 0.4754 - val_accuracy: 0.7597 - val_loss: 0.5046\n",
      "Epoch 31/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7671 - loss: 0.4751 - val_accuracy: 0.7532 - val_loss: 0.5103\n",
      "Epoch 32/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7720 - loss: 0.4734 - val_accuracy: 0.7662 - val_loss: 0.5034\n",
      "Epoch 33/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7704 - loss: 0.4751 - val_accuracy: 0.7532 - val_loss: 0.5246\n",
      "Epoch 34/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7590 - loss: 0.4763 - val_accuracy: 0.7532 - val_loss: 0.5057\n",
      "Epoch 35/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7671 - loss: 0.4720 - val_accuracy: 0.7662 - val_loss: 0.5051\n",
      "Epoch 36/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7834 - loss: 0.4769 - val_accuracy: 0.7727 - val_loss: 0.5077\n",
      "Epoch 37/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7655 - loss: 0.4743 - val_accuracy: 0.7662 - val_loss: 0.5067\n",
      "Epoch 38/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7687 - loss: 0.4746 - val_accuracy: 0.7532 - val_loss: 0.5119\n",
      "Epoch 39/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7720 - loss: 0.4735 - val_accuracy: 0.7597 - val_loss: 0.5019\n",
      "Epoch 40/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7720 - loss: 0.4734 - val_accuracy: 0.7338 - val_loss: 0.5293\n",
      "Epoch 41/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7769 - loss: 0.4775 - val_accuracy: 0.7338 - val_loss: 0.5099\n",
      "Epoch 42/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7687 - loss: 0.4745 - val_accuracy: 0.7468 - val_loss: 0.5078\n",
      "Epoch 43/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7736 - loss: 0.4750 - val_accuracy: 0.7468 - val_loss: 0.5200\n",
      "Epoch 44/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7655 - loss: 0.4736 - val_accuracy: 0.7662 - val_loss: 0.5045\n",
      "Epoch 45/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7687 - loss: 0.4748 - val_accuracy: 0.7403 - val_loss: 0.5227\n",
      "Epoch 46/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7720 - loss: 0.4763 - val_accuracy: 0.7727 - val_loss: 0.5088\n",
      "Epoch 47/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7769 - loss: 0.4738 - val_accuracy: 0.7468 - val_loss: 0.5147\n",
      "Epoch 48/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7638 - loss: 0.4759 - val_accuracy: 0.7468 - val_loss: 0.5080\n",
      "Epoch 49/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7671 - loss: 0.4746 - val_accuracy: 0.7532 - val_loss: 0.5047\n",
      "Epoch 50/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7638 - loss: 0.4750 - val_accuracy: 0.7597 - val_loss: 0.5069\n",
      "Epoch 51/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7687 - loss: 0.4742 - val_accuracy: 0.7532 - val_loss: 0.5103\n",
      "Epoch 52/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7704 - loss: 0.4739 - val_accuracy: 0.7597 - val_loss: 0.5010\n",
      "Epoch 53/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7736 - loss: 0.4745 - val_accuracy: 0.7597 - val_loss: 0.5037\n",
      "Epoch 54/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7720 - loss: 0.4756 - val_accuracy: 0.7597 - val_loss: 0.5026\n",
      "Epoch 55/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7704 - loss: 0.4731 - val_accuracy: 0.7597 - val_loss: 0.5050\n",
      "Epoch 56/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7736 - loss: 0.4735 - val_accuracy: 0.7468 - val_loss: 0.5173\n",
      "Epoch 57/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7704 - loss: 0.4724 - val_accuracy: 0.7597 - val_loss: 0.5007\n",
      "Epoch 58/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7704 - loss: 0.4728 - val_accuracy: 0.7468 - val_loss: 0.5236\n",
      "Epoch 59/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7736 - loss: 0.4755 - val_accuracy: 0.7597 - val_loss: 0.5120\n",
      "Epoch 60/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7704 - loss: 0.4732 - val_accuracy: 0.7662 - val_loss: 0.5031\n",
      "Epoch 61/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7704 - loss: 0.4733 - val_accuracy: 0.7662 - val_loss: 0.5022\n",
      "Epoch 62/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7736 - loss: 0.4748 - val_accuracy: 0.7662 - val_loss: 0.4965\n",
      "Epoch 63/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7655 - loss: 0.4750 - val_accuracy: 0.7792 - val_loss: 0.4969\n",
      "Epoch 64/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7687 - loss: 0.4747 - val_accuracy: 0.7792 - val_loss: 0.5045\n",
      "Epoch 65/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7801 - loss: 0.4737 - val_accuracy: 0.7662 - val_loss: 0.5034\n",
      "Epoch 66/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7818 - loss: 0.4728 - val_accuracy: 0.7597 - val_loss: 0.5105\n",
      "Epoch 67/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7671 - loss: 0.4765 - val_accuracy: 0.7468 - val_loss: 0.5178\n",
      "Epoch 68/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7720 - loss: 0.4763 - val_accuracy: 0.7468 - val_loss: 0.5092\n",
      "Epoch 69/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7687 - loss: 0.4735 - val_accuracy: 0.7597 - val_loss: 0.5005\n",
      "Epoch 70/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7736 - loss: 0.4743 - val_accuracy: 0.7597 - val_loss: 0.5077\n",
      "Epoch 71/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7655 - loss: 0.4727 - val_accuracy: 0.7662 - val_loss: 0.5016\n",
      "Epoch 72/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7638 - loss: 0.4737 - val_accuracy: 0.7662 - val_loss: 0.5018\n",
      "Epoch 73/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7687 - loss: 0.4736 - val_accuracy: 0.7727 - val_loss: 0.5015\n",
      "Epoch 74/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7687 - loss: 0.4732 - val_accuracy: 0.7727 - val_loss: 0.5069\n",
      "Epoch 75/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7704 - loss: 0.4732 - val_accuracy: 0.7468 - val_loss: 0.5168\n",
      "Epoch 76/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7752 - loss: 0.4737 - val_accuracy: 0.7532 - val_loss: 0.5059\n",
      "Epoch 77/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7671 - loss: 0.4745 - val_accuracy: 0.7597 - val_loss: 0.5098\n",
      "Epoch 78/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7687 - loss: 0.4734 - val_accuracy: 0.7532 - val_loss: 0.5088\n",
      "Epoch 79/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7720 - loss: 0.4739 - val_accuracy: 0.7597 - val_loss: 0.5031\n",
      "Epoch 80/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7720 - loss: 0.4728 - val_accuracy: 0.7662 - val_loss: 0.5047\n",
      "Epoch 81/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7818 - loss: 0.4726 - val_accuracy: 0.7727 - val_loss: 0.4995\n",
      "Epoch 82/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7622 - loss: 0.4741 - val_accuracy: 0.7662 - val_loss: 0.5022\n",
      "Epoch 83/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7720 - loss: 0.4721 - val_accuracy: 0.7597 - val_loss: 0.5076\n",
      "Epoch 84/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7687 - loss: 0.4747 - val_accuracy: 0.7597 - val_loss: 0.5068\n",
      "Epoch 85/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7671 - loss: 0.4729 - val_accuracy: 0.7597 - val_loss: 0.5068\n",
      "Epoch 86/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7752 - loss: 0.4724 - val_accuracy: 0.7468 - val_loss: 0.5163\n",
      "Epoch 87/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7671 - loss: 0.4743 - val_accuracy: 0.7468 - val_loss: 0.5168\n",
      "Epoch 88/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7687 - loss: 0.4741 - val_accuracy: 0.7468 - val_loss: 0.5164\n",
      "Epoch 89/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7736 - loss: 0.4746 - val_accuracy: 0.7597 - val_loss: 0.5057\n",
      "Epoch 90/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7687 - loss: 0.4724 - val_accuracy: 0.7403 - val_loss: 0.5164\n",
      "Epoch 91/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7687 - loss: 0.4727 - val_accuracy: 0.7468 - val_loss: 0.5032\n",
      "Epoch 92/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7704 - loss: 0.4745 - val_accuracy: 0.7468 - val_loss: 0.5087\n",
      "Epoch 93/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7736 - loss: 0.4740 - val_accuracy: 0.7468 - val_loss: 0.5065\n",
      "Epoch 94/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7720 - loss: 0.4736 - val_accuracy: 0.7662 - val_loss: 0.4997\n",
      "Epoch 95/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7720 - loss: 0.4720 - val_accuracy: 0.7468 - val_loss: 0.5127\n",
      "Epoch 96/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7704 - loss: 0.4726 - val_accuracy: 0.7403 - val_loss: 0.5088\n",
      "Epoch 97/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7671 - loss: 0.4749 - val_accuracy: 0.7597 - val_loss: 0.5027\n",
      "Epoch 98/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7736 - loss: 0.4724 - val_accuracy: 0.7662 - val_loss: 0.5015\n",
      "Epoch 99/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7736 - loss: 0.4728 - val_accuracy: 0.7597 - val_loss: 0.5033\n",
      "Epoch 100/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7769 - loss: 0.4740 - val_accuracy: 0.7532 - val_loss: 0.5090\n",
      "Epoch 101/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7769 - loss: 0.4724 - val_accuracy: 0.7468 - val_loss: 0.5132\n",
      "Epoch 102/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7687 - loss: 0.4740 - val_accuracy: 0.7468 - val_loss: 0.5072\n",
      "Epoch 103/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7736 - loss: 0.4738 - val_accuracy: 0.7468 - val_loss: 0.5029\n",
      "Epoch 104/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7720 - loss: 0.4733 - val_accuracy: 0.7403 - val_loss: 0.5128\n",
      "Epoch 105/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7720 - loss: 0.4714 - val_accuracy: 0.7338 - val_loss: 0.5151\n",
      "Epoch 106/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7687 - loss: 0.4716 - val_accuracy: 0.7597 - val_loss: 0.5035\n",
      "Epoch 107/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7671 - loss: 0.4717 - val_accuracy: 0.7468 - val_loss: 0.5217\n",
      "Epoch 108/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7638 - loss: 0.4733 - val_accuracy: 0.7403 - val_loss: 0.5061\n",
      "Epoch 109/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7671 - loss: 0.4714 - val_accuracy: 0.7468 - val_loss: 0.5053\n",
      "Epoch 110/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7736 - loss: 0.4733 - val_accuracy: 0.7468 - val_loss: 0.5153\n",
      "Epoch 111/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7671 - loss: 0.4731 - val_accuracy: 0.7468 - val_loss: 0.5076\n",
      "Epoch 112/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7704 - loss: 0.4733 - val_accuracy: 0.7532 - val_loss: 0.5085\n",
      "Epoch 113/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7704 - loss: 0.4725 - val_accuracy: 0.7403 - val_loss: 0.5144\n",
      "Epoch 114/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7769 - loss: 0.4738 - val_accuracy: 0.7468 - val_loss: 0.5061\n",
      "Epoch 115/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7687 - loss: 0.4722 - val_accuracy: 0.7468 - val_loss: 0.5115\n",
      "Epoch 116/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7638 - loss: 0.4752 - val_accuracy: 0.7597 - val_loss: 0.5085\n",
      "Epoch 117/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7704 - loss: 0.4737 - val_accuracy: 0.7468 - val_loss: 0.5112\n",
      "Epoch 118/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7752 - loss: 0.4731 - val_accuracy: 0.7662 - val_loss: 0.5027\n",
      "Epoch 119/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7704 - loss: 0.4721 - val_accuracy: 0.7532 - val_loss: 0.5070\n",
      "Epoch 120/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7720 - loss: 0.4726 - val_accuracy: 0.7532 - val_loss: 0.5109\n",
      "Epoch 121/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7655 - loss: 0.4742 - val_accuracy: 0.7597 - val_loss: 0.5042\n",
      "Epoch 122/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7687 - loss: 0.4732 - val_accuracy: 0.7532 - val_loss: 0.5082\n",
      "Epoch 123/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7687 - loss: 0.4723 - val_accuracy: 0.7597 - val_loss: 0.5090\n",
      "Epoch 124/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7720 - loss: 0.4728 - val_accuracy: 0.7468 - val_loss: 0.5229\n",
      "Epoch 125/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.7671 - loss: 0.4725 - val_accuracy: 0.7597 - val_loss: 0.5038\n",
      "Epoch 126/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7655 - loss: 0.4717 - val_accuracy: 0.7597 - val_loss: 0.5054\n",
      "Epoch 127/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7704 - loss: 0.4733 - val_accuracy: 0.7597 - val_loss: 0.5050\n",
      "Epoch 128/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7704 - loss: 0.4730 - val_accuracy: 0.7597 - val_loss: 0.5044\n",
      "Epoch 129/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7704 - loss: 0.4726 - val_accuracy: 0.7468 - val_loss: 0.5111\n",
      "Epoch 130/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7704 - loss: 0.4732 - val_accuracy: 0.7468 - val_loss: 0.5136\n",
      "Epoch 131/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7704 - loss: 0.4719 - val_accuracy: 0.7532 - val_loss: 0.5081\n",
      "Epoch 132/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7752 - loss: 0.4737 - val_accuracy: 0.7468 - val_loss: 0.5078\n",
      "Epoch 133/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7720 - loss: 0.4729 - val_accuracy: 0.7662 - val_loss: 0.5042\n",
      "Epoch 134/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7720 - loss: 0.4724 - val_accuracy: 0.7597 - val_loss: 0.5099\n",
      "Epoch 135/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7752 - loss: 0.4726 - val_accuracy: 0.7597 - val_loss: 0.5123\n",
      "Epoch 136/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7704 - loss: 0.4735 - val_accuracy: 0.7468 - val_loss: 0.5153\n",
      "Epoch 137/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7720 - loss: 0.4719 - val_accuracy: 0.7597 - val_loss: 0.5094\n",
      "Epoch 138/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7752 - loss: 0.4727 - val_accuracy: 0.7532 - val_loss: 0.5146\n",
      "Epoch 139/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7736 - loss: 0.4712 - val_accuracy: 0.7468 - val_loss: 0.5225\n",
      "Epoch 140/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7736 - loss: 0.4731 - val_accuracy: 0.7403 - val_loss: 0.5128\n",
      "Epoch 141/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7736 - loss: 0.4727 - val_accuracy: 0.7597 - val_loss: 0.5062\n",
      "Epoch 142/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7606 - loss: 0.4725 - val_accuracy: 0.7597 - val_loss: 0.5119\n",
      "Epoch 143/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7720 - loss: 0.4726 - val_accuracy: 0.7532 - val_loss: 0.5051\n",
      "Epoch 144/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7704 - loss: 0.4733 - val_accuracy: 0.7532 - val_loss: 0.5114\n",
      "Epoch 145/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7687 - loss: 0.4718 - val_accuracy: 0.7597 - val_loss: 0.5089\n",
      "Epoch 146/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7704 - loss: 0.4715 - val_accuracy: 0.7468 - val_loss: 0.5168\n",
      "Epoch 147/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7736 - loss: 0.4714 - val_accuracy: 0.7662 - val_loss: 0.5114\n",
      "Epoch 148/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7720 - loss: 0.4724 - val_accuracy: 0.7662 - val_loss: 0.5112\n",
      "Epoch 149/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7736 - loss: 0.4720 - val_accuracy: 0.7338 - val_loss: 0.5206\n",
      "Epoch 150/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7720 - loss: 0.4715 - val_accuracy: 0.7273 - val_loss: 0.5164\n",
      "Epoch 151/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7720 - loss: 0.4729 - val_accuracy: 0.7468 - val_loss: 0.5135\n",
      "Epoch 152/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7687 - loss: 0.4717 - val_accuracy: 0.7532 - val_loss: 0.5126\n",
      "Epoch 153/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7736 - loss: 0.4733 - val_accuracy: 0.7532 - val_loss: 0.5114\n",
      "Epoch 154/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7704 - loss: 0.4728 - val_accuracy: 0.7792 - val_loss: 0.5062\n",
      "Epoch 155/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7720 - loss: 0.4728 - val_accuracy: 0.7792 - val_loss: 0.5094\n",
      "Epoch 156/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7655 - loss: 0.4734 - val_accuracy: 0.7662 - val_loss: 0.5174\n",
      "Epoch 157/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7769 - loss: 0.4731 - val_accuracy: 0.7468 - val_loss: 0.5221\n",
      "Epoch 158/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7638 - loss: 0.4719 - val_accuracy: 0.7532 - val_loss: 0.5075\n",
      "Epoch 159/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7704 - loss: 0.4722 - val_accuracy: 0.7597 - val_loss: 0.5069\n",
      "Epoch 160/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7704 - loss: 0.4715 - val_accuracy: 0.7532 - val_loss: 0.5179\n",
      "Epoch 161/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7720 - loss: 0.4735 - val_accuracy: 0.7468 - val_loss: 0.5153\n",
      "Epoch 162/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7704 - loss: 0.4737 - val_accuracy: 0.7532 - val_loss: 0.5093\n",
      "Epoch 163/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7687 - loss: 0.4715 - val_accuracy: 0.7597 - val_loss: 0.5059\n",
      "Epoch 164/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7687 - loss: 0.4741 - val_accuracy: 0.7468 - val_loss: 0.5109\n",
      "Epoch 165/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7752 - loss: 0.4710 - val_accuracy: 0.7468 - val_loss: 0.5096\n",
      "Epoch 166/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7687 - loss: 0.4712 - val_accuracy: 0.7468 - val_loss: 0.5079\n",
      "Epoch 167/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7704 - loss: 0.4720 - val_accuracy: 0.7403 - val_loss: 0.5123\n",
      "Epoch 168/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7704 - loss: 0.4727 - val_accuracy: 0.7468 - val_loss: 0.5100\n",
      "Epoch 169/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7752 - loss: 0.4714 - val_accuracy: 0.7403 - val_loss: 0.5253\n",
      "Epoch 170/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7687 - loss: 0.4726 - val_accuracy: 0.7468 - val_loss: 0.5251\n",
      "Epoch 171/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7720 - loss: 0.4728 - val_accuracy: 0.7468 - val_loss: 0.5143\n",
      "Epoch 172/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7720 - loss: 0.4723 - val_accuracy: 0.7662 - val_loss: 0.5071\n",
      "Epoch 173/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7720 - loss: 0.4702 - val_accuracy: 0.7468 - val_loss: 0.5224\n",
      "Epoch 174/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7752 - loss: 0.4733 - val_accuracy: 0.7468 - val_loss: 0.5103\n",
      "Epoch 175/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7687 - loss: 0.4717 - val_accuracy: 0.7532 - val_loss: 0.5161\n",
      "Epoch 176/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7736 - loss: 0.4731 - val_accuracy: 0.7532 - val_loss: 0.5147\n",
      "Epoch 177/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7752 - loss: 0.4721 - val_accuracy: 0.7403 - val_loss: 0.5217\n",
      "Epoch 178/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7720 - loss: 0.4737 - val_accuracy: 0.7468 - val_loss: 0.5149\n",
      "Epoch 179/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7752 - loss: 0.4725 - val_accuracy: 0.7338 - val_loss: 0.5196\n",
      "Epoch 180/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7687 - loss: 0.4748 - val_accuracy: 0.7468 - val_loss: 0.5117\n",
      "Epoch 181/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7704 - loss: 0.4727 - val_accuracy: 0.7597 - val_loss: 0.5060\n",
      "Epoch 182/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7736 - loss: 0.4713 - val_accuracy: 0.7662 - val_loss: 0.5035\n",
      "Epoch 183/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7720 - loss: 0.4716 - val_accuracy: 0.7662 - val_loss: 0.5090\n",
      "Epoch 184/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7736 - loss: 0.4728 - val_accuracy: 0.7662 - val_loss: 0.5075\n",
      "Epoch 185/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7704 - loss: 0.4728 - val_accuracy: 0.7662 - val_loss: 0.5042\n",
      "Epoch 186/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7704 - loss: 0.4726 - val_accuracy: 0.7662 - val_loss: 0.5050\n",
      "Epoch 187/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7752 - loss: 0.4722 - val_accuracy: 0.7468 - val_loss: 0.5138\n",
      "Epoch 188/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7720 - loss: 0.4707 - val_accuracy: 0.7468 - val_loss: 0.5136\n",
      "Epoch 189/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7704 - loss: 0.4719 - val_accuracy: 0.7468 - val_loss: 0.5111\n",
      "Epoch 190/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7671 - loss: 0.4727 - val_accuracy: 0.7532 - val_loss: 0.5160\n",
      "Epoch 191/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7752 - loss: 0.4718 - val_accuracy: 0.7468 - val_loss: 0.5075\n",
      "Epoch 192/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7704 - loss: 0.4713 - val_accuracy: 0.7403 - val_loss: 0.5174\n",
      "Epoch 193/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7720 - loss: 0.4715 - val_accuracy: 0.7403 - val_loss: 0.5213\n",
      "Epoch 194/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7720 - loss: 0.4705 - val_accuracy: 0.7532 - val_loss: 0.5062\n",
      "Epoch 195/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7671 - loss: 0.4726 - val_accuracy: 0.7468 - val_loss: 0.5142\n",
      "Epoch 196/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7687 - loss: 0.4728 - val_accuracy: 0.7532 - val_loss: 0.5093\n",
      "Epoch 197/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7752 - loss: 0.4711 - val_accuracy: 0.7403 - val_loss: 0.5290\n",
      "Epoch 198/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7687 - loss: 0.4720 - val_accuracy: 0.7532 - val_loss: 0.5066\n",
      "Epoch 199/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7704 - loss: 0.4709 - val_accuracy: 0.7468 - val_loss: 0.5125\n",
      "Epoch 200/200\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7720 - loss: 0.4713 - val_accuracy: 0.7468 - val_loss: 0.5128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e3b5f62eb0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=200,initial_epoch=6,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f148a82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
